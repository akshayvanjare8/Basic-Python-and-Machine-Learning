{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlCLZf3Fqptx"
   },
   "source": [
    "#Classfication practice_ sonar dataset\n",
    "\n",
    "\n",
    "The Sonar Dataset involves the prediction of whether or not an object\n",
    "is a mine or a rock given the strength of sonar returns at different\n",
    "angles.\n",
    "It is a binary (2-class) classification problem. The number of\n",
    "observations for each class is not balanced. There are 208 observations\n",
    "with 60 input variables and 1 output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vA2o3MmxqZ93"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "rkIY-3yerJeb",
    "outputId": "c9bf21a6-49ea-4083-bacc-3110f2201e22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.02</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>0.1609</th>\n",
       "      <th>0.1582</th>\n",
       "      <th>0.2238</th>\n",
       "      <th>0.0645</th>\n",
       "      <th>0.066</th>\n",
       "      <th>0.2273</th>\n",
       "      <th>0.31</th>\n",
       "      <th>0.2999</th>\n",
       "      <th>0.5078</th>\n",
       "      <th>0.4797</th>\n",
       "      <th>0.5783</th>\n",
       "      <th>0.5071</th>\n",
       "      <th>0.4328</th>\n",
       "      <th>0.555</th>\n",
       "      <th>0.6711</th>\n",
       "      <th>0.6415</th>\n",
       "      <th>0.7104</th>\n",
       "      <th>0.808</th>\n",
       "      <th>0.6791</th>\n",
       "      <th>0.3857</th>\n",
       "      <th>0.1307</th>\n",
       "      <th>0.2604</th>\n",
       "      <th>0.5121</th>\n",
       "      <th>0.7547</th>\n",
       "      <th>0.8537</th>\n",
       "      <th>0.8507</th>\n",
       "      <th>0.6692</th>\n",
       "      <th>0.6097</th>\n",
       "      <th>0.4943</th>\n",
       "      <th>0.2744</th>\n",
       "      <th>0.051</th>\n",
       "      <th>0.2834</th>\n",
       "      <th>0.2825</th>\n",
       "      <th>0.4256</th>\n",
       "      <th>0.2641</th>\n",
       "      <th>0.1386</th>\n",
       "      <th>0.1051</th>\n",
       "      <th>0.1343</th>\n",
       "      <th>0.0383</th>\n",
       "      <th>0.0324</th>\n",
       "      <th>0.0232</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.018</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.009</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.3914</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.3788</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.5320</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.4293</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.2261</td>\n",
       "      <td>0.1729</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.3973</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.3559</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.2655</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.6193</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.4292</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7262</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.5103</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.2881</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.4181</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.6343</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>0.5122</td>\n",
       "      <td>0.2074</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.5782</td>\n",
       "      <td>0.5389</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0.4778</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>0.3807</td>\n",
       "      <td>0.4158</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>0.3296</td>\n",
       "      <td>0.2707</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.02  0.0371  0.0428  0.0207  0.0954  ...   0.018  0.0084   0.009  0.0032  R\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044  R\n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078  R\n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117  R\n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094  R\n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  ...  0.0057  0.0027  0.0051  0.0062  R\n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/content/sonar.all-data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbbztXXxxZdI",
    "outputId": "8d3283ef-58e1-4b1b-8448-dc584dc0e85e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 207 entries, 0 to 206\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0.02    207 non-null    float64\n",
      " 1   0.0371  207 non-null    float64\n",
      " 2   0.0428  207 non-null    float64\n",
      " 3   0.0207  207 non-null    float64\n",
      " 4   0.0954  207 non-null    float64\n",
      " 5   0.0986  207 non-null    float64\n",
      " 6   0.1539  207 non-null    float64\n",
      " 7   0.1601  207 non-null    float64\n",
      " 8   0.3109  207 non-null    float64\n",
      " 9   0.2111  207 non-null    float64\n",
      " 10  0.1609  207 non-null    float64\n",
      " 11  0.1582  207 non-null    float64\n",
      " 12  0.2238  207 non-null    float64\n",
      " 13  0.0645  207 non-null    float64\n",
      " 14  0.066   207 non-null    float64\n",
      " 15  0.2273  207 non-null    float64\n",
      " 16  0.31    207 non-null    float64\n",
      " 17  0.2999  207 non-null    float64\n",
      " 18  0.5078  207 non-null    float64\n",
      " 19  0.4797  207 non-null    float64\n",
      " 20  0.5783  207 non-null    float64\n",
      " 21  0.5071  207 non-null    float64\n",
      " 22  0.4328  207 non-null    float64\n",
      " 23  0.555   207 non-null    float64\n",
      " 24  0.6711  207 non-null    float64\n",
      " 25  0.6415  207 non-null    float64\n",
      " 26  0.7104  207 non-null    float64\n",
      " 27  0.808   207 non-null    float64\n",
      " 28  0.6791  207 non-null    float64\n",
      " 29  0.3857  207 non-null    float64\n",
      " 30  0.1307  207 non-null    float64\n",
      " 31  0.2604  207 non-null    float64\n",
      " 32  0.5121  207 non-null    float64\n",
      " 33  0.7547  207 non-null    float64\n",
      " 34  0.8537  207 non-null    float64\n",
      " 35  0.8507  207 non-null    float64\n",
      " 36  0.6692  207 non-null    float64\n",
      " 37  0.6097  207 non-null    float64\n",
      " 38  0.4943  207 non-null    float64\n",
      " 39  0.2744  207 non-null    float64\n",
      " 40  0.051   207 non-null    float64\n",
      " 41  0.2834  207 non-null    float64\n",
      " 42  0.2825  207 non-null    float64\n",
      " 43  0.4256  207 non-null    float64\n",
      " 44  0.2641  207 non-null    float64\n",
      " 45  0.1386  207 non-null    float64\n",
      " 46  0.1051  207 non-null    float64\n",
      " 47  0.1343  207 non-null    float64\n",
      " 48  0.0383  207 non-null    float64\n",
      " 49  0.0324  207 non-null    float64\n",
      " 50  0.0232  207 non-null    float64\n",
      " 51  0.0027  207 non-null    float64\n",
      " 52  0.0065  207 non-null    float64\n",
      " 53  0.0159  207 non-null    float64\n",
      " 54  0.0072  207 non-null    float64\n",
      " 55  0.0167  207 non-null    float64\n",
      " 56  0.018   207 non-null    float64\n",
      " 57  0.0084  207 non-null    float64\n",
      " 58  0.009   207 non-null    float64\n",
      " 59  0.0032  207 non-null    float64\n",
      " 60  R       207 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 98.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "vZHnz-XJ4KNs",
    "outputId": "47f68943-fd3d-4cb9-8435-6615c8c1fa74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.02</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>0.1609</th>\n",
       "      <th>0.1582</th>\n",
       "      <th>0.2238</th>\n",
       "      <th>0.0645</th>\n",
       "      <th>0.066</th>\n",
       "      <th>0.2273</th>\n",
       "      <th>0.31</th>\n",
       "      <th>0.2999</th>\n",
       "      <th>0.5078</th>\n",
       "      <th>0.4797</th>\n",
       "      <th>0.5783</th>\n",
       "      <th>0.5071</th>\n",
       "      <th>0.4328</th>\n",
       "      <th>0.555</th>\n",
       "      <th>0.6711</th>\n",
       "      <th>0.6415</th>\n",
       "      <th>0.7104</th>\n",
       "      <th>0.808</th>\n",
       "      <th>0.6791</th>\n",
       "      <th>0.3857</th>\n",
       "      <th>0.1307</th>\n",
       "      <th>0.2604</th>\n",
       "      <th>0.5121</th>\n",
       "      <th>0.7547</th>\n",
       "      <th>0.8537</th>\n",
       "      <th>0.8507</th>\n",
       "      <th>0.6692</th>\n",
       "      <th>0.6097</th>\n",
       "      <th>0.4943</th>\n",
       "      <th>0.2744</th>\n",
       "      <th>0.051</th>\n",
       "      <th>0.2834</th>\n",
       "      <th>0.2825</th>\n",
       "      <th>0.4256</th>\n",
       "      <th>0.2641</th>\n",
       "      <th>0.1386</th>\n",
       "      <th>0.1051</th>\n",
       "      <th>0.1343</th>\n",
       "      <th>0.0383</th>\n",
       "      <th>0.0324</th>\n",
       "      <th>0.0232</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.018</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.009</th>\n",
       "      <th>0.0032</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029208</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>0.054053</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.104599</td>\n",
       "      <td>0.121591</td>\n",
       "      <td>0.134677</td>\n",
       "      <td>0.177361</td>\n",
       "      <td>0.208245</td>\n",
       "      <td>0.236376</td>\n",
       "      <td>0.250666</td>\n",
       "      <td>0.273544</td>\n",
       "      <td>0.297689</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.379217</td>\n",
       "      <td>0.416495</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.504797</td>\n",
       "      <td>0.563449</td>\n",
       "      <td>0.609209</td>\n",
       "      <td>0.624841</td>\n",
       "      <td>0.648010</td>\n",
       "      <td>0.673223</td>\n",
       "      <td>0.675444</td>\n",
       "      <td>0.700148</td>\n",
       "      <td>0.702115</td>\n",
       "      <td>0.693473</td>\n",
       "      <td>0.641895</td>\n",
       "      <td>0.581871</td>\n",
       "      <td>0.506281</td>\n",
       "      <td>0.439903</td>\n",
       "      <td>0.416761</td>\n",
       "      <td>0.401535</td>\n",
       "      <td>0.390343</td>\n",
       "      <td>0.382597</td>\n",
       "      <td>0.362331</td>\n",
       "      <td>0.338353</td>\n",
       "      <td>0.324986</td>\n",
       "      <td>0.311385</td>\n",
       "      <td>0.290403</td>\n",
       "      <td>0.278269</td>\n",
       "      <td>0.246368</td>\n",
       "      <td>0.213053</td>\n",
       "      <td>0.196909</td>\n",
       "      <td>0.160738</td>\n",
       "      <td>0.122537</td>\n",
       "      <td>0.091217</td>\n",
       "      <td>0.051995</td>\n",
       "      <td>0.020366</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.006523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>0.046583</td>\n",
       "      <td>0.055669</td>\n",
       "      <td>0.059247</td>\n",
       "      <td>0.061897</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.118311</td>\n",
       "      <td>0.134741</td>\n",
       "      <td>0.132923</td>\n",
       "      <td>0.140264</td>\n",
       "      <td>0.141262</td>\n",
       "      <td>0.164075</td>\n",
       "      <td>0.205158</td>\n",
       "      <td>0.232975</td>\n",
       "      <td>0.264213</td>\n",
       "      <td>0.261947</td>\n",
       "      <td>0.258614</td>\n",
       "      <td>0.263225</td>\n",
       "      <td>0.258434</td>\n",
       "      <td>0.256373</td>\n",
       "      <td>0.250335</td>\n",
       "      <td>0.239555</td>\n",
       "      <td>0.245520</td>\n",
       "      <td>0.237768</td>\n",
       "      <td>0.246252</td>\n",
       "      <td>0.237631</td>\n",
       "      <td>0.240818</td>\n",
       "      <td>0.220864</td>\n",
       "      <td>0.212917</td>\n",
       "      <td>0.213389</td>\n",
       "      <td>0.206907</td>\n",
       "      <td>0.230499</td>\n",
       "      <td>0.257756</td>\n",
       "      <td>0.262755</td>\n",
       "      <td>0.239546</td>\n",
       "      <td>0.212655</td>\n",
       "      <td>0.199210</td>\n",
       "      <td>0.179076</td>\n",
       "      <td>0.170717</td>\n",
       "      <td>0.169137</td>\n",
       "      <td>0.139308</td>\n",
       "      <td>0.132795</td>\n",
       "      <td>0.151924</td>\n",
       "      <td>0.134254</td>\n",
       "      <td>0.087155</td>\n",
       "      <td>0.062496</td>\n",
       "      <td>0.036029</td>\n",
       "      <td>0.013673</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.005038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.066950</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.096750</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.133450</td>\n",
       "      <td>0.165750</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>0.205500</td>\n",
       "      <td>0.241950</td>\n",
       "      <td>0.299050</td>\n",
       "      <td>0.350450</td>\n",
       "      <td>0.397550</td>\n",
       "      <td>0.406350</td>\n",
       "      <td>0.455250</td>\n",
       "      <td>0.540450</td>\n",
       "      <td>0.524800</td>\n",
       "      <td>0.543550</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>0.533950</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.414250</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>0.284100</td>\n",
       "      <td>0.257350</td>\n",
       "      <td>0.217550</td>\n",
       "      <td>0.178550</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.174250</td>\n",
       "      <td>0.172450</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.126850</td>\n",
       "      <td>0.094450</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.044950</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.225100</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.265500</td>\n",
       "      <td>0.281900</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.700700</td>\n",
       "      <td>0.701200</td>\n",
       "      <td>0.722100</td>\n",
       "      <td>0.754500</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.731700</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.607400</td>\n",
       "      <td>0.490600</td>\n",
       "      <td>0.430300</td>\n",
       "      <td>0.390300</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.101050</td>\n",
       "      <td>0.134150</td>\n",
       "      <td>0.153050</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.351500</td>\n",
       "      <td>0.386950</td>\n",
       "      <td>0.453050</td>\n",
       "      <td>0.536050</td>\n",
       "      <td>0.660050</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>0.809450</td>\n",
       "      <td>0.818050</td>\n",
       "      <td>0.832150</td>\n",
       "      <td>0.852250</td>\n",
       "      <td>0.873350</td>\n",
       "      <td>0.874550</td>\n",
       "      <td>0.893800</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.901850</td>\n",
       "      <td>0.852350</td>\n",
       "      <td>0.736950</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.585700</td>\n",
       "      <td>0.556750</td>\n",
       "      <td>0.584400</td>\n",
       "      <td>0.591400</td>\n",
       "      <td>0.553950</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>0.438750</td>\n",
       "      <td>0.430550</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.389150</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.325050</td>\n",
       "      <td>0.267650</td>\n",
       "      <td>0.229750</td>\n",
       "      <td>0.200650</td>\n",
       "      <td>0.154750</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.068950</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.016750</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.008550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>0.734200</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.713100</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965700</td>\n",
       "      <td>0.930600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.929700</td>\n",
       "      <td>0.899500</td>\n",
       "      <td>0.824600</td>\n",
       "      <td>0.773300</td>\n",
       "      <td>0.776200</td>\n",
       "      <td>0.703400</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.333900</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0.02      0.0371      0.0428  ...      0.0084       0.009      0.0032\n",
       "count  207.000000  207.000000  207.000000  ...  207.000000  207.000000  207.000000\n",
       "mean     0.029208    0.038443    0.043837  ...    0.007947    0.007936    0.006523\n",
       "std      0.023038    0.033040    0.038521  ...    0.006485    0.006196    0.005038\n",
       "min      0.001500    0.000600    0.001500  ...    0.000300    0.000100    0.000600\n",
       "25%      0.013300    0.016400    0.018900  ...    0.003600    0.003650    0.003100\n",
       "50%      0.022800    0.030800    0.034200  ...    0.005800    0.006300    0.005300\n",
       "75%      0.035800    0.048100    0.058200  ...    0.010400    0.010350    0.008550\n",
       "max      0.137100    0.233900    0.305900  ...    0.044000    0.036400    0.043900\n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYk1syyH4hSl",
    "outputId": "fb545997-d312-4a7c-e379-6e4f41122ef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02      0\n",
       "0.0371    0\n",
       "0.0428    0\n",
       "0.0207    0\n",
       "0.0954    0\n",
       "         ..\n",
       "0.018     0\n",
       "0.0084    0\n",
       "0.009     0\n",
       "0.0032    0\n",
       "R         0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for the missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JkiVBPHC5EyL"
   },
   "outputs": [],
   "source": [
    "#label enoding target data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['R']=le.fit_transform(df[\"R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "v1FM3p4W9APf"
   },
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VkFFC0Zu9xHv"
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yIsemfUIDW8Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAxG4oRJ_16D"
   },
   "source": [
    "**Create pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FFhaCL8h_04r"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline_lr=Pipeline([('logistic classifier',LogisticRegression())])\n",
    "pipeline_svc=Pipeline([('support vector',SVC())])\n",
    "pipeline_knn=Pipeline([('Nearest Neighbor',KNeighborsClassifier())])\n",
    "pipeline_Nb=Pipeline([('Naive Bayes',GaussianNB())])\n",
    "pipelines=[pipeline_lr,pipeline_svc,pipeline_knn,pipeline_Nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qd9TANKr-Brf"
   },
   "outputs": [],
   "source": [
    "pipe_dict={0:\"logistic classifier\",1:\"support vector\",2:\"Nearest Neighbor\",3:\"Naive Bayes\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Y43qUzcU-j10"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  for pipe in pipelines:\n",
    "    pipe.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KUfDZg-nG7os"
   },
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "  for i,model in enumerate(pipelines):\n",
    "    print(\"For\",pipe_dict[i],\" Accuracy is : \", model.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "G8uTmbazJBNV"
   },
   "outputs": [],
   "source": [
    "def bestmodel():\n",
    "  best_accuracy=0\n",
    "  best_classifier=0\n",
    "  best_pipline=\"\"\n",
    "  for i,model in enumerate(pipelines):\n",
    "    if best_accuracy < model.score(xtest,ytest):\n",
    "      best_accuracy=model.score(xtest,ytest)\n",
    "      best_pipline=model\n",
    "      best_classifier=pipe_dict[i]\n",
    "\n",
    "  print(\"best accuracy model= {}, with accuracy = {}\".format(best_classifier,best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvkd1x8IWvrZ"
   },
   "source": [
    "**For original data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0n3N-ijMY4u",
    "outputId": "d4843baa-7917-41ce-c115-0af3ad3e8b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For logistic classifier  Accuracy is :  0.7619047619047619\n",
      "For support vector  Accuracy is :  0.7619047619047619\n",
      "For Nearest Neighbor  Accuracy is :  0.7380952380952381\n",
      "For Naive Bayes  Accuracy is :  0.6428571428571429\n",
      "best accuracy model= logistic classifier, with accuracy = 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "a=train()\n",
    "b=accuracy()\n",
    "c=bestmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NBcybJLhJumb"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline_lr=Pipeline([('Scaler',StandardScaler()),\n",
    "                      ('logistic classifier',LogisticRegression()),])\n",
    "pipeline_svc=Pipeline([('Scaler',StandardScaler()),\n",
    "                       ('support vector',SVC())])\n",
    "pipeline_knn=Pipeline([('Scaler',StandardScaler()),\n",
    "                       ('Nearest Neighbor',KNeighborsClassifier())])\n",
    "pipeline_Nb=Pipeline([('Scaler',StandardScaler()),\n",
    "                      ('Naive Bayes',GaussianNB())])\n",
    "pipelines=[pipeline_lr,pipeline_svc,pipeline_knn,pipeline_Nb]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvMoLaU-W22x"
   },
   "source": [
    "**For scaled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxAHqYQEK7kG",
    "outputId": "0845c030-5667-4cad-f4bd-a6eb9b7a5c13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For logistic classifier  Accuracy is :  0.7619047619047619\n",
      "For support vector  Accuracy is :  0.7619047619047619\n",
      "For Nearest Neighbor  Accuracy is :  0.7142857142857143\n",
      "For Naive Bayes  Accuracy is :  0.6428571428571429\n",
      "best accuracy model= logistic classifier, with accuracy = 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "a=train()\n",
    "b=accuracy()\n",
    "c=bestmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "JBXhfEj5Lqx8",
    "outputId": "4cea240e-5ade-4d1d-9b07-3f637a79f542"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fada47c39d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(data=df,x=\"R\",kind=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5KP1VSedPIV"
   },
   "source": [
    "**For balanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "r4azuExGNOb3"
   },
   "outputs": [],
   "source": [
    "R=df[df[\"R\"]==0].index\n",
    "M=df[df[\"R\"]==1].index\n",
    "random_index=np.array(np.random.choice(R,len(M),replace=False))\n",
    "udersample_index=np.concatenate([fraud,random_index])\n",
    "undersample=df.iloc[udersample_index,:]\n",
    "x=undersample.drop(columns=[\"R\"])\n",
    "y=undersample[\"R\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "tpHmmXtoPVqS",
    "outputId": "606e1d9d-684d-42f1-8793-252e4cfebd57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fad98529f90>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(data=undersample,x=\"R\",kind=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlSVgiZ9OwQA",
    "outputId": "8c5d3374-3055-496a-aa7b-3700d1f74253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For logistic classifier  Accuracy is :  0.6923076923076923\n",
      "For support vector  Accuracy is :  0.8461538461538461\n",
      "For Nearest Neighbor  Accuracy is :  0.8205128205128205\n",
      "For Naive Bayes  Accuracy is :  0.6410256410256411\n",
      "best accuracy model= support vector, with accuracy = 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "a=train()\n",
    "b=accuracy()\n",
    "c=bestmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "KLBeZ2-ZO4MA"
   },
   "outputs": [],
   "source": [
    "#over sampling of data\n",
    "R=df[df[\"R\"]==0].index\n",
    "M=df[df[\"R\"]==1].index\n",
    "\n",
    "#random_index for 'M' with majority class size\n",
    "random_index=np.array(np.random.choice(M,len(R),replace=True))\n",
    "\n",
    "oversample_index=np.concatenate([R,random_index])\n",
    "oversample=df.iloc[oversample_index,:]\n",
    "x=oversample.drop(columns=[\"R\"])\n",
    "y=oversample[\"R\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--DNb287c64I",
    "outputId": "1c3e5e5e-5285-40bf-98bc-52b8bc5dfad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For logistic classifier  Accuracy is :  0.8444444444444444\n",
      "For support vector  Accuracy is :  0.9111111111111111\n",
      "For Nearest Neighbor  Accuracy is :  0.9333333333333333\n",
      "For Naive Bayes  Accuracy is :  0.6888888888888889\n",
      "best accuracy model= Nearest Neighbor, with accuracy = 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "a=train()\n",
    "b=accuracy()\n",
    "c=bestmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqEzFM5BdDQu"
   },
   "source": [
    "**Conclusion :**\n",
    "\n",
    "best accuracy model= Nearest Neighbor, with accuracy = 0.9333333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhXt7ZGXdA17"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FST_Classification Practice_Sonar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
